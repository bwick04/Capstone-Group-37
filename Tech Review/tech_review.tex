\documentclass[letterpaper,10pt,onecolumn,draftclsnofoot]{IEEEtran}
\usepackage{times}

\usepackage[english]{babel}
\usepackage[margin=0.75in]{geometry}

\usepackage{graphicx}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\title{Object Speed Tracking}
\author{Tech Review\\Alex Bailey, Ben Wick, Dylan Washburne\\CS 461, Fall Term}

\begin{document}

\begin{titlepage}

\maketitle

\begin{abstract}
While we could consider whether we would use a singular camera or multiple, there is really no debate here.
Stereoscopic cameras carry such an advantage for a project like this, we are making that decision.
 
\end{abstract}

\end{titlepage}

\section{Live Data Feed} %Alex

Both images simultaneously
Both images plus depth information
Singular image with depth

\section{Live Compression} %Dylan

No compression
Camera live compresses
Computer live compresses

\section{Long-Term Storage}%Alex

1 feed+data, 
2 feeds no data to be re-calculated, 
1 feed data baked into video

\section{Computer Vision Library} %Ben

The three options for Computer Vision software packages include OpenCV, VXL, and AForge.
Selecting a good Computer Vision library is essential. The goal of the CV library is to provide us with a large array of programming functions that we are able to utilize.
The library selected must be able to support our needs of being able to identify and track objects in real time.
The criteria that will be evaluated are languages used, features available, and performance.
OpenCV is one of the most commonly used libraries for computer vision.
According to their website, they offer over 2500 algorithms that include identifying objects.
AForge is also another Computer vision library that is able to detect the motion of objects.
AForge isn't as commonly used as OpenCV but it is also a great alternative because it also offers motion tracking.
Based on the criteria needed for computer vision library, OpenCV has a large number of algorithms that we will be able to use as well as performs faster than VXL.

\section{Computer Vision Underlying Algorithm} %Ben

Haar cascades
Background subraction

...
...

\section{Synchronization} %Alex

two cameras, each sends images and computer works to compensate for any desyncronization
two cameras with global shutter, send back 2 images
2 cameras which do image splicing and send back spliced image to computer

\section{UI Overlay} %Dylan

Open Broadcaster Software
VideoMeld
Camtasia

Goals for the selected software are to show the video stream as it is given, as well as placing boses around objects points sent from the backend's recognition software.

Criteria for each of these softwares include performance overhead and the ability to add more overlay components in real time.

\begin{tabular}{ l l }
  OBS Studio & OBS is a fairly common overlay software.  It has a stable level of performance and is able to pop in elements for the overlay at any time.  It is undetermined as of yet if this software would be able to make these additional elements go to dynamic positions on screen. \\ \hline
  VideoMeld & This seems to be from before the era of livestreams, and though it has a wide variety for overlay objects, I cannot find any way for it to support dynamically occuring objects in the overlay  \\ \hline
  Camtasia & This only works live through an extra plugin and it has significant overhead in the process.  Dynamic overlay objects do not seem to be supported. \\
\end{tabular}

Discussion

I choose OBS based on what is discussed above.


\section{Existing Speed Formulas} %Dylan

make our own
...
...

\section{Long-Term Compression} %Alex 
%Lossless
%Lossy
%No Compression

The options that we will be looking at are Xvid, FFV1, OpenH264.
The goals for this piece of the project is to compress the video after it has been displayed to the user, to be kept for long term, should they be needed at a later date.
With our product, it is likely that the user will be leaving our product running for a significant amount of time, possibly hours.
When this happens, video files can become rather large.
This will become a problem for long term storage if our product is used often.
So, the answer to this problem is to use a compression encoder/decoder, codec.
This will reduce the size of the video as much as possible.
There are several factors to consider when looking at video compression codecs.
The first is whether or not it is lossless.
When compressing information, especially pictures and videos, the compression codecs will often save space by removing data, often in the form of merging pixels, leading to a lower resolution, these are called lossy codecs.
While a lossless codec is obviously prefered, there are not many lossless video compression methods available and they often have limited compression.
Lossy codecs generally offer a greater reduction of file size, with the amount of data lost, depending on the codec.
This could be an acceptable tradeoff, depending on the size of the file and amount of quality lost.
Second is the amount of compression, often expressed as a ratio.
This is the ratio of the size of the original video file to the size of the compressed file.
This can be difficult to judge as some videos compress better than other depending on the what is being recorded.
Third, price is almost always a factor, as it is in this case.
If there is an open source alternative that is comparable to a paid version, then the open source would be more favorable.

Xvid is a an open source codec alternatice to a commercially sold codec, DivX [2].
Xvid claims to be able to "compress video at a ration of 200:1 or more"[1].
While impressive, this is likely only under certain conditions.
Xvid is a "'lossy' compression but aims at removing just those picture details that are not important for human perception"[1].

FFV1 is a lossless video codec that is a part of FFmpeg a "leading multimedia framework, able to decode, encode, transcode, mux, demux, steam, filter and play pretty much anything that humans and machines have created" [3].
Two sources have reported FFV1's compression ration as roughly 100GB per hour to 45-50GB per hour [4], approximately 2:1, to rougly 1.2:1 to 2.5:1.

H.264 is a video codec that was created by International Telecommunication Union, that has become "an industry standard for video compression" [6].
Cisco has recently decided to release an open source version under a BSD license and cover the royalties for anyone using their binary files [7].
While this would allow the our product to use the H.264 codex, it would restrict us in the need to only use their binaries and always keep them up to date.
Should their be an issue, this could cause significant legal trouble.
H.264 has a lossless version that has a ration of roughly 2:1 [8].


%possible sections:  

%how the video feed is stored (1 feed+data, 2 feeds no data to be re-calculated, 1 feed data overlayed)
%connection speeds
%live compression
%long-term compression
%video to database storage
%mono- vs bi-focal
%computer vision
%speed formula
%legal accountability
%internal clocks/global shutters (syncronization)

\end{document}
